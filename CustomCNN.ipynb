{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a393de",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, input_channels:int, nodes:list, kernels:list, num_classes:int=10):\n",
    "        \"\"\"\n",
    "        input channels is the number of channels in the input data (e.g., 1 for grayscale, 3 for RGB)\n",
    "        nodes is a list of nodes per layer i.e. 128, 64, 32\n",
    " kernals is a list of the kernals used per layer\n",
    " number of classes is thenumber of outputs (the number of emotions to possibly classify)\n",
    " this creates the neural network with the specified layers and the kernals\n",
    "        \"\"\"\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        assert len(nodes) == len(kernels), \"nodes and kernels must have the same length\"\n",
    "\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "\n",
    "        for out_channels, k in zip(nodes, kernels):\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=k, padding=k//2)\n",
    "            layers.append(conv)\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))  \n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(nodes[-1], num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))  \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, input_channels:int, nodes:list, kernels:list, num_classes:int=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        assert len(nodes) == len(kernels), \"nodes and kernels must have the same length\"\n",
    "\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        for out_channels, k in zip(nodes, kernels):\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=k, padding=k//2)\n",
    "            layers += [conv, nn.ReLU(), nn.MaxPool2d(2)]\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(nodes[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# SAVE / LOAD FUNCTIONS\n",
    "# ==============================\n",
    "\n",
    "def save_customcnn(model, filename=\"customcnn.pth\", infofile=\"customcnn_info.txt\", **meta):\n",
    "    \"\"\"Save model weights + architecture info in same folder.\"\"\"\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    info = {\n",
    "        \"input_channels\": meta.get(\"input_channels\"),\n",
    "        \"nodes\": meta.get(\"nodes\"),\n",
    "        \"kernels\": meta.get(\"kernels\"),\n",
    "        \"num_classes\": meta.get(\"num_classes\"),\n",
    "    }\n",
    "    with open(infofile, \"w\") as f:\n",
    "        f.write(json.dumps(info))\n",
    "    print(f\"✅ Model saved as {filename} with metadata {infofile}\")\n",
    "\n",
    "\n",
    "def load_customcnn(weightfile=\"customcnn.pth\", infofile=\"customcnn_info.txt\"):\n",
    "    \"\"\"Reload a CustomCNN using saved metadata + weights.\"\"\"\n",
    "    with open(infofile, \"r\") as f:\n",
    "        info = json.loads(f.read())\n",
    "    model = CustomCNN(\n",
    "        input_channels=info[\"input_channels\"],\n",
    "        nodes=info[\"nodes\"],\n",
    "        kernels=info[\"kernels\"],\n",
    "        num_classes=info[\"num_classes\"],\n",
    "    )\n",
    "    model.load_state_dict(torch.load(weightfile, map_location=torch.device(\"cpu\")))\n",
    "    model.eval()\n",
    "    print(f\"✅ Model loaded from {weightfile}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# TVM CONVERSION FUNCTION\n",
    "# ==============================\n",
    "\n",
    "def export_to_tvm(model, input_shape=(1, 3, 64, 64), target=\"llvm\", output_prefix=\"tvm_model\"):\n",
    "    \"\"\"Convert a PyTorch CNN to a TVM deployable format.\"\"\"\n",
    "    model.eval()\n",
    "    example_input = torch.randn(input_shape)\n",
    "\n",
    "    # 1. Trace PyTorch model\n",
    "    traced = torch.jit.trace(model, example_input)\n",
    "\n",
    "    # 2. Convert to TVM Relay\n",
    "    shape_list = [(\"input0\", example_input.shape)]\n",
    "    mod, params = relay.frontend.from_pytorch(traced, shape_list)\n",
    "\n",
    "    # 3. Build TVM module\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "    # 4. Save compiled outputs\n",
    "    lib.export_library(f\"{output_prefix}.so\")\n",
    "    with open(f\"{output_prefix}.json\", \"w\") as f_json:\n",
    "        f_json.write(lib.graph_json)\n",
    "    with open(f\"{output_prefix}.params\", \"wb\") as f_params:\n",
    "        f_params.write(relay.save_param_dict(lib.params))\n",
    "\n",
    "    print(f\"✅ TVM module exported: {output_prefix}.so / .json / .params\")\n",
    "    return lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dec16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CustomCNN(\n",
    "    input_channels=3,\n",
    "    nodes=[32, 64, 128],\n",
    "    kernels=[3, 3, 5],\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c175df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
